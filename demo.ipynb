{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adapted from [CLASSIFYING NAMES WITH A CHARACTER-LEVEL RNN](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html#classifying-names-with-a-character-level-rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from [here](https://download.pytorch.org/tutorial/data.zip) into the current directory and extract it into `data` directory before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path):\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/names/Czech.txt',\n",
       " 'data/names/German.txt',\n",
       " 'data/names/Arabic.txt',\n",
       " 'data/names/Japanese.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_files('data/names/*.txt')[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn' and c in all_letters\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "print(unicode_to_ascii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "def readlines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "for filename in find_files('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readlines(filename)\n",
    "    category_lines[category] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Czech', 'German', 'Arabic', 'Japanese']\n",
      "['Abl', 'Adsit', 'Ajdrna', 'Alt']\n"
     ]
    }
   ],
   "source": [
    "print(all_categories[:4])\n",
    "print(category_lines['Czech'][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_to_index(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letter_to_tensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letter_to_index(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def line_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for idx, letter in enumerate(line):\n",
    "        tensor[idx][0][letter_to_index(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LstmCell\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.lstm = LstmCell(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm.reset_state()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.output_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 100\n",
    "net = Net(n_letters, hidden_size, len(all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_example():\n",
    "    cat = random.choice(all_categories)\n",
    "    cat_t = torch.tensor([all_categories.index(cat)], dtype=torch.long)\n",
    "\n",
    "    line = random.choice(category_lines[cat])\n",
    "    line_t = line_to_tensor(line)\n",
    "    \n",
    "    return cat, line, cat_t, line_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category = Vietnamese / line = Han\n",
      "category = Russian / line = Galena\n",
      "category = Greek / line = Kouros\n",
      "category = Japanese / line = Fuse\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    category, line, category_tensor, line_tensor = random_training_example()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), learning_rate,\n",
    "                                momentum=0.9, alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer):\n",
    "    n_iters = 200000\n",
    "    print_every = 5000\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    cur_loss = 0\n",
    "    correct_count = 0\n",
    "    losses = []\n",
    "    \n",
    "    for idx in range(1, n_iters+1):\n",
    "        cat, line, cat_t, line_t = random_training_example()\n",
    "\n",
    "        net.reset_state()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for char_t in line_t:\n",
    "            output = net(char_t)\n",
    "\n",
    "        loss = criterion(output, cat_t)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        \n",
    "        guess, guess_i = category_from_output(output)\n",
    "        if guess == cat:\n",
    "            correct_count += 1\n",
    "            \n",
    "        if idx == 1 or idx % print_every == 0:\n",
    "            losses = losses[-100:]\n",
    "            progress = idx / n_iters * 100\n",
    "            precision = correct_count / print_every * 100\n",
    "            correct = '✓' if guess == cat else '✗ (answer %s)' % cat\n",
    "            print('%d(%d%%) loss %.4f(mean %.4f) precision %.4f%% %s / %s %s' % (\n",
    "                idx, progress, loss, sum(losses)/len(losses), precision, line, guess, correct))\n",
    "            correct_count = 0\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1(0%) loss 3.0800(mean 3.0800) precision 0.0000% Hwang / French ✗ (answer Korean)\n",
      "5000(2%) loss 1.2659(mean 1.6370) precision 32.8000% Dubanowski / Polish ✓\n",
      "10000(5%) loss 1.5804(mean 1.3333) precision 51.8400% Vasyuk / Czech ✗ (answer Russian)\n",
      "15000(7%) loss 2.1582(mean 1.2622) precision 57.9000% Del olmo / Italian ✗ (answer Spanish)\n",
      "20000(10%) loss 0.2749(mean 1.0271) precision 63.6000% Gui / Chinese ✓\n",
      "25000(12%) loss 3.1362(mean 0.9027) precision 68.0000% Albuquerque / Portuguese ✗ (answer Spanish)\n",
      "30000(15%) loss 0.1172(mean 0.7063) precision 71.6800% Mustafa / Arabic ✓\n",
      "35000(17%) loss 3.6725(mean 0.7841) precision 74.3200% Sappe / Dutch ✗ (answer Czech)\n",
      "40000(20%) loss 1.1175(mean 0.6720) precision 76.8400% Ozimuk / Japanese ✗ (answer Czech)\n",
      "45000(22%) loss 1.5211(mean 0.7740) precision 78.6200% Wilchek / Polish ✗ (answer Czech)\n",
      "50000(25%) loss 0.5574(mean 0.6166) precision 80.7800% Rocco / Italian ✓\n",
      "55000(27%) loss 0.0009(mean 0.4168) precision 82.1600% Shimazu / Japanese ✓\n",
      "60000(30%) loss 2.9439(mean 0.4178) precision 83.3400% Neusser / German ✗ (answer Czech)\n",
      "65000(32%) loss 0.0597(mean 0.5852) precision 83.8800% Long / Chinese ✓\n",
      "70000(35%) loss 0.0000(mean 0.4822) precision 84.5200% O'Reilly / Irish ✓\n",
      "75000(37%) loss 0.0287(mean 0.3692) precision 85.0800% Elizondo / Spanish ✓\n",
      "80000(40%) loss 0.0084(mean 0.4424) precision 85.9600% Heinrich / German ✓\n",
      "85000(42%) loss 0.0001(mean 0.5234) precision 86.7600% Bekhteev / Russian ✓\n",
      "90000(45%) loss 2.9169(mean 0.4398) precision 87.0400% Wang / Korean ✗ (answer Chinese)\n",
      "95000(47%) loss 0.6918(mean 0.5503) precision 88.3800% Chi / Korean ✓\n",
      "100000(50%) loss 0.0006(mean 0.3879) precision 86.8800% Zhizhchenko / Russian ✓\n",
      "105000(52%) loss 0.0065(mean 0.4035) precision 88.0800% Ganem / Arabic ✓\n",
      "110000(55%) loss 0.0841(mean 0.3860) precision 88.6200% Dresdner / German ✓\n",
      "115000(57%) loss 0.0706(mean 0.2699) precision 88.7000% Neuman / German ✓\n",
      "120000(60%) loss 0.0110(mean 0.3695) precision 89.7800% Reynders / Dutch ✓\n",
      "125000(62%) loss 0.0489(mean 0.3170) precision 89.3600% Ezakiya / Japanese ✓\n",
      "130000(65%) loss 0.0049(mean 0.3216) precision 90.1200% Czajka / Polish ✓\n",
      "135000(67%) loss 0.0407(mean 0.2422) precision 89.7400% Cardona / Spanish ✓\n",
      "140000(70%) loss 0.0474(mean 0.3787) precision 89.6000% Solos / Spanish ✓\n",
      "145000(72%) loss 0.1336(mean 0.3317) precision 89.8000% Guerra / Portuguese ✓\n",
      "150000(75%) loss 1.7116(mean 0.4286) precision 90.6400% Speight / German ✗ (answer English)\n",
      "155000(77%) loss 0.0033(mean 0.3380) precision 90.8000% Iniguez / Spanish ✓\n",
      "160000(80%) loss 0.0302(mean 0.3581) precision 90.7400% an / Vietnamese ✓\n",
      "165000(82%) loss 0.0054(mean 0.2509) precision 90.2400% Kerr / Scottish ✓\n",
      "170000(85%) loss 0.0009(mean 0.4340) precision 90.2400% Fei / Chinese ✓\n",
      "175000(87%) loss 0.0043(mean 0.2758) precision 90.5000% O'Keeffe / Irish ✓\n",
      "180000(90%) loss 0.0068(mean 0.3588) precision 90.0400% Kerr / Scottish ✓\n",
      "185000(92%) loss 1.6379(mean 0.3797) precision 91.6600% Remih / Irish ✗ (answer Russian)\n",
      "190000(95%) loss 0.0361(mean 0.2626) precision 91.3200% Rothenberg / German ✓\n",
      "195000(97%) loss 0.0002(mean 0.3817) precision 91.3600% Hasyanov / Russian ✓\n",
      "200000(100%) loss 1.6634(mean 0.2419) precision 91.1600% Atiyeh / Russian ✗ (answer Arabic)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-69.6351, -67.4072, -61.4861, -64.5850, -71.0838, -71.5544, -60.0541,\n",
       "          -70.6511, -66.6004, -65.3142, -66.0218, -74.3977, -70.6490, -67.3909,\n",
       "          -74.3360, -69.1282, -71.7948, -75.9072]], grad_fn=<AddmmBackward>),\n",
       " 1.6634140014648438)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(net, criterion, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
